---
title: "Adding a Model"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{adding_a_model}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

The portalcasting package provides the ability to add functions both to a
local copy of the repository for testing as well as to contribute to the
base set of models provided within the package (and thus executed in the
main respository.

For the purposes here, consider that you are interested in adding a model
named "newmod" to the forecasting suite. 

## Model input

All of the information needed to make a new forecast can be found in the
`data/` subdirectory, including rodent and weather data files as well as
a `metadata.yaml` file that contains the metadata controls to make sure
the models match each other.

## Model requirements

In order to realize "newmod", you need to create an R script named
`newmod.R` and located within the `models/` subdirectory. 

Forecasts generated by each model are saved in the `tmp/` subdirectory 
before being combined into a single file, used to build ensemble 
forecasts, saved in the predictions directory, and (if integrated into 
the Portal Predictions repository) archived. To facilitate integration,
your model must generate a table of forecasts with specific columns names,
saved to a file in `tmp/` that ends in `[modelname]forecasts.csv`. It must 
also generate a table of AIC values, also with specific column names, saved
to a file in `tmp/` named [modelname]forecasts_model_aic.csv. 


### Columns of the `-forecasts.csv` file need to be:  

`date`: date on which the model was run. In the format `'YYYY-MM-DD'`. 
(If hindcasting is done then the date will be a later date than `forecastyear`
or `forecastmonth`.)  
 
`forecastmonth`: the month of a prediction.  

`forecastyear`: the year of a prediction.

`newmoonnumber`: the new moon ID of a prediction (new moon 1 is the first
sample on 1977-07-16). 
 
`currency`: the type of value being predicted. Valid values are: 
`"abundance"`, `"richness"`, `"biomass"`, and `"energy"`, although only
`"abundance"` is currently implemented.

`model`: the name of the model.

`level`: the spatial level of the site being predicted. Valid values are: 
`"All"`, `"Controls"`, `"FullExclosure"`, `"KratExclosure"`, and `"Plot1"`, 
`"Plot2"`, through to `"Plot24"`, although only `"All"` and `"Controls"`
are currently implemented.

`species`: the species being predicted. Valid values are all the rodent 
species codes ("AH", "BA", "PB", "PH", "PI", "PP", "PX", "DM", "DO", "DX",
"DS", "NA", "OL", "OX", "OT", "PF", "PE", "PL", "PM", "RF", "RM", "RO", 
"RX", "UR", "SF", "SH", "SO", "SX", "SS", "ST", "SA", "CS", "CV", "EO", 
"SC", "SU", "UL", "AS", "AB", "CM", "CQ", "CB", "PC", "PU", "UP", "PG", 
"US", "SB", "ZL") or "total" for the combined prediction of all species. 

`estimate`: the mean value of the prediction.  

`LowerPI`: the lower bound of the predicted 90% CI.

`UpperPI`: the upper bound of the predicted 90% CI.   

`fit_start_newmoon`: the first newmoonnumber in the data used to make the
prediction.

`fit_end_newmoon`: the last newmoonnumber in the data used to make the
prediction.

`initial_newmoon`: the first newmoonnumber for which predictions are made 
in the set.

`currency`, `level`, and `species` are the three unique things by which
models will be compared with each other. That is, a model predicting 
`level`: `"all"`, `currency`: `"abundance"`, `species`: `"AH"` will only
be compared against models making those same predictions.

### Columns of the `-forecasts_model_aic.csv` file need to be:

`date`, `currency`, `model`, `level`, `species`, `fit_start_newmoon`, 
`fit_end_newmoon`, and `initial_newmoon` as in the `-forecasts.csv` file.

`aic`: [Akaike Information 
Criterion](https://en.wikipedia.org/wiki/Akaike_information_criterion) value.

## Adding models locally

Firstly, set up a base local version of the Portal Predictions repository
via `setup_dir()`.

Then, add your model script `newmod.R` to the `models/` subdirectory along
with the existing base model set added by `setup_dir()`. 

You can then execute the new model within the forecasting (or hindcasting)
pipeline as defined via `portalcast()`. To run only "newmod", use

```
portalcast(all_options(model = "newmod"))
```
or, to run "newmod" in addition to the existing set of models, use
```
portalcast(all_options(model = models(add = "newmod")))
```

## Contributing models to the base set

The prefabricated (base) set of models available for use within the 
Portal Predictions pipeline is controlled through a few functions
that will need to be ammended to add a new model. In addition to the 
model requirements outlined above, inclusion in the base set via 
portalcasting requires additional coding specifications be met to 
ensure proper use by the package and pipeline.

`fill_models()` fills the `models/` subdirectory with the R scripts
used to drive the model running via calls to `write_model()` for each
of the desired models. `fill_models()` is controlled by the options list
generated by `models_options()`, which includes an element named
`model` that needs to list the name of every model within the base set,
and which (by default) is generated by the `models()` function. So, to 
update the default options lists, simply **add the name of the model to
the vector of model names returned by `models(set = "prefab")`**.

`fill_models()` executes a series of functions (one for each model)
that are named as `<modelname>_options` (*e.g.*, `AutoArima_options()`),
which define the specific options (`options_model` argument, generally 
created by `model_options()`) required for the given model within the
`write_model()` function. Thus, to ensure the model script can be written,
you will need to **create a function called `newmod_options`**, which 
functionally sets the inputs to  `model_options()` for the specific model, 
and **include newmod_options` in the `R/` subdirectory of the portalcasting
package folder** (likely a local clone of the repository). 

For each model, `write_model()` makes a call to the `model_template()` 
function, which creates the associated text of the associated R script 
based on the input options. For "newmod" to integrate into the pipeline, you
need to **write a function with the same name as your model** (`newmod` here).
Given current implementation, if the the model does not need covariates
(weather and NDVI data), the function should have a first argument
that can take the `data/all.csv` and `data/controls.csv` files, a second
argument that can take the `data/metadata.yaml` file, and a third argument
that is `level` and should be able to toggle between `"all"` and `"controls"`.
For reference, see `AutoArima()`.

If the model does need covariates, the function should have a first argument
that can take the `data/all.csv` and `data/controls.csv` files, a second
argument that can take the `data/covariates`, a third argument that can take
the `data/metadata.yaml` file, a fourth argument that is `level` and should 
be able to toggle between `"all"` and `"controls"`, and a fifth argument named
`lag` that should be able to take an integer value that defines the lag between
covariates and rodents in newmoon steps. For references, see `pevGARCH()`. 
Further, if your model requires covariates and uses a lag larger than 0 but 
shorter than the current minimum non-0 lag (6 moons), you should **update the
`min_lag` argument default in `all_options()`, `data_options()`, and
`covariates_options()`**. 

Output from your model function will be put into `save_forecast_output()`, 
which combines output from the `"all"` and `"controls"` forecasts based on the 
assumption of a two-element list (`"forecast"` and `"aic"`) from each run of 
the function. Thus, to work within the pipeline specifically, **your model 
function needs to return a list with two elements corresponding to the output
requirements outline above**. Once completed, **the `newmod` function needs to
be included within the `R/` directory of the portalcasting repository**. If
your model function requires any external code, **additional libraries need to
be added to the DESCRIPTION file**. 

Having added the `newmod` and `newmod_options` functions to the package and 
updated the existing functions (`models()` and, if necessary, 
`all_options()`, `data_options()`, and `covariates_options()`) and 
dependencies, you should then **update the documentation using 
`devtools::document()` and re-load the package using `devtools::load_all()`**.
Then, use the updated package to **verify that newmod is properly integrated 
into the pipeline under default settings by running `setup_dir()` then 
`portalcast()`**, which should execute cleanly. You should **then run 
`cleanup_dir()` to remove the temporary files and folders from the repository**.

Once the code has run successfully (including the integration of the output
from "newmod" into the ensemble) and the respository has been cleaned up,
**create a Pull Request to the portalcasting repository**

